{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\n\nWe'll be using TensorFlow and Keras to build our computer vision model, and using TPUs to both train our model and make predictions. ","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.039382,"end_time":"2020-11-19T21:45:23.042097","exception":false,"start_time":"2020-11-19T21:45:23.002715","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Tensor Processing Units (TPUs)\n\nTensor Processing Units (TPUs) are hardware accelerators that are specialized for deep learning tasks. ","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","papermill":{"duration":0.035886,"end_time":"2020-11-19T21:45:23.118837","exception":false,"start_time":"2020-11-19T21:45:23.082951","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Set up environment","metadata":{"papermill":{"duration":0.037375,"end_time":"2020-11-19T21:45:23.192515","exception":false,"start_time":"2020-11-19T21:45:23.15514","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import math, re, os\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom kaggle_datasets import KaggleDatasets\nfrom tensorflow import keras\nfrom functools import partial\nfrom sklearn.model_selection import train_test_split\nprint(\"Tensorflow version \" + tf.__version__)","metadata":{"papermill":{"duration":6.890298,"end_time":"2020-11-19T21:45:30.119979","exception":false,"start_time":"2020-11-19T21:45:23.229681","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-11T10:32:02.526965Z","iopub.execute_input":"2022-08-11T10:32:02.527640Z","iopub.status.idle":"2022-08-11T10:32:09.349900Z","shell.execute_reply.started":"2022-08-11T10:32:02.527542Z","shell.execute_reply":"2022-08-11T10:32:09.348949Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Detect TPU\nWhat we're doing with our code here is making sure that we'll be sending our data across a TPU. What you're looking for is a printout of `Number of replicas: 8`, corresponding to the 8 cores of a TPU. If your printout instead says `Number of replicas: 1` you likely do not have TPUs enabled in your notebook.   \n","metadata":{"papermill":{"duration":0.037444,"end_time":"2020-11-19T21:45:30.195328","exception":false,"start_time":"2020-11-19T21:45:30.157884","status":"completed"},"tags":[]}},{"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)","metadata":{"papermill":{"duration":4.150374,"end_time":"2020-11-19T21:45:34.382816","exception":false,"start_time":"2020-11-19T21:45:30.232442","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-11T10:32:09.351263Z","iopub.execute_input":"2022-08-11T10:32:09.351556Z","iopub.status.idle":"2022-08-11T10:32:15.455237Z","shell.execute_reply.started":"2022-08-11T10:32:09.351525Z","shell.execute_reply":"2022-08-11T10:32:15.454184Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Set up variables\nWe'll set up some of our variables for our notebook here. \n","metadata":{"papermill":{"duration":0.038122,"end_time":"2020-11-19T21:45:34.458722","exception":false,"start_time":"2020-11-19T21:45:34.4206","status":"completed"},"tags":[]}},{"cell_type":"code","source":"AUTOTUNE = tf.data.experimental.AUTOTUNE\nGCS_PATH = KaggleDatasets().get_gcs_path()\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync   # Batch size will be 128 when TPU is on.\nIMAGE_SIZE = [512, 512]          # Defining the image size. Means image array is 512x512\nCLASSES = ['0', '1', '2', '3', '4']     # Corresponding to the 5 output classes\nEPOCHS = 25","metadata":{"papermill":{"duration":145.219568,"end_time":"2020-11-19T21:47:59.715925","exception":false,"start_time":"2020-11-19T21:45:34.496357","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-11T10:32:15.456590Z","iopub.execute_input":"2022-08-11T10:32:15.456844Z","iopub.status.idle":"2022-08-11T10:32:15.852184Z","shell.execute_reply.started":"2022-08-11T10:32:15.456815Z","shell.execute_reply":"2022-08-11T10:32:15.851305Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"print(AUTOTUNE)\nprint(GCS_PATH)\nprint(BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-08-11T10:32:15.855946Z","iopub.execute_input":"2022-08-11T10:32:15.856224Z","iopub.status.idle":"2022-08-11T10:32:15.862161Z","shell.execute_reply.started":"2022-08-11T10:32:15.856193Z","shell.execute_reply":"2022-08-11T10:32:15.861020Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Load the data\n\nThe data we're working with have been formatted into `TFRecords`, which are a format for storing a sequence of binary records. `TFRecords` work _really_ well with TPUs, and allow us to send a small number of large files across the TPU for processing.   \n\nTo learn more about `TFRecords` and maybe even try creating them yourself, check out this **[TFRecords Basics notebook](https://www.kaggle.com/ryanholbrook/tfrecords-basics)** and **[corresponding video](https://youtu.be/KgjaC9VeOi8)** from Kaggle Data Scientist Ryan Holbrook.  \n\nBecause our data consists of `training` and `test` images only, we're going to split our `training` data into `training` and `validation` data using the `train_test_split()` function. ","metadata":{"papermill":{"duration":0.037843,"end_time":"2020-11-19T21:47:59.792061","exception":false,"start_time":"2020-11-19T21:47:59.754218","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Decode the data\nIn the code chunk below we'll set up a series of functions that allow us to convert our images into tensors so that we can utilize them in our model. We'll also normalize our data. Our images are using a \"Red, Blue, Green (RBG)\" scale that has a range of [0, 255], and by normalizing it we'll set each pixel's value to a number in the range of [0, 1]. ","metadata":{"papermill":{"duration":0.038439,"end_time":"2020-11-19T21:47:59.869037","exception":false,"start_time":"2020-11-19T21:47:59.830598","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def decode_image(image):\n    image = tf.image.decode_jpeg(image, channels=3)  # 3 Channels belong to RBG category.\n    image = tf.cast(image, tf.float32) / 255.0        # normalizing image\n    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n    return image","metadata":{"papermill":{"duration":0.04859,"end_time":"2020-11-19T21:47:59.955731","exception":false,"start_time":"2020-11-19T21:47:59.907141","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-11T10:32:15.863779Z","iopub.execute_input":"2022-08-11T10:32:15.864001Z","iopub.status.idle":"2022-08-11T10:32:15.874391Z","shell.execute_reply.started":"2022-08-11T10:32:15.863977Z","shell.execute_reply":"2022-08-11T10:32:15.873578Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"Our `features` are represented by the term `image` and our `prediction target` by the term `target`.  \n\nAlso notice that this function accounts for unlabeled images. This is because our test image doesn't have any labels.  ","metadata":{"papermill":{"duration":0.039515,"end_time":"2020-11-19T21:48:00.034969","exception":false,"start_time":"2020-11-19T21:47:59.995454","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def read_tfrecord(example, labeled):\n    tfrecord_format = {\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"target\": tf.io.FixedLenFeature([], tf.int64)\n    } if labeled else {\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"image_name\": tf.io.FixedLenFeature([], tf.string)\n    }\n    example = tf.io.parse_single_example(example, tfrecord_format)\n    image = decode_image(example['image'])\n    if labeled:\n        label = tf.cast(example['target'], tf.int32)\n        return image, label\n    idnum = example['image_name']\n    return image, idnum","metadata":{"papermill":{"duration":0.052475,"end_time":"2020-11-19T21:48:00.127039","exception":false,"start_time":"2020-11-19T21:48:00.074564","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-11T10:32:15.875851Z","iopub.execute_input":"2022-08-11T10:32:15.876121Z","iopub.status.idle":"2022-08-11T10:32:15.886241Z","shell.execute_reply.started":"2022-08-11T10:32:15.876094Z","shell.execute_reply":"2022-08-11T10:32:15.885488Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"We'll use the following function to load our dataset. One of the advantages of a TPU is that we can run multiple files across the TPU at once, and this accounts for the speed advantages of using a TPU. To capitalize on that, we want to make sure that we're using data as soon as it streams in, rather than creating a data streaming bottleneck.","metadata":{"papermill":{"duration":0.038946,"end_time":"2020-11-19T21:48:00.205445","exception":false,"start_time":"2020-11-19T21:48:00.166499","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def load_dataset(filenames, labeled=True, ordered=False):\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False # disable order, increase speed\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE) # automatically interleaves reads from multiple files\n    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n    dataset = dataset.map(partial(read_tfrecord, labeled=labeled), num_parallel_calls=AUTOTUNE)  # # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n    return dataset","metadata":{"papermill":{"duration":0.073623,"end_time":"2020-11-19T21:48:00.328703","exception":false,"start_time":"2020-11-19T21:48:00.25508","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-11T10:32:15.887615Z","iopub.execute_input":"2022-08-11T10:32:15.887871Z","iopub.status.idle":"2022-08-11T10:32:15.898122Z","shell.execute_reply.started":"2022-08-11T10:32:15.887836Z","shell.execute_reply":"2022-08-11T10:32:15.897376Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## A note on using train_test_split()\nWe used `train_test_split()` to create both a `training` and `validation` dataset. One can also use cross validation technique as well. ","metadata":{"papermill":{"duration":0.03958,"end_time":"2020-11-19T21:48:00.416432","exception":false,"start_time":"2020-11-19T21:48:00.376852","status":"completed"},"tags":[]}},{"cell_type":"code","source":"TRAINING_FILENAMES, VALID_FILENAMES = train_test_split(\n    tf.io.gfile.glob(GCS_PATH + '/train_tfrecords/ld_train*.tfrec'),\n    test_size=0.2, random_state=5\n)\n\nTEST_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/test_tfrecords/ld_test*.tfrec')","metadata":{"papermill":{"duration":0.225941,"end_time":"2020-11-19T21:48:00.687385","exception":false,"start_time":"2020-11-19T21:48:00.461444","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-11T10:32:15.899498Z","iopub.execute_input":"2022-08-11T10:32:15.899970Z","iopub.status.idle":"2022-08-11T10:32:16.083595Z","shell.execute_reply.started":"2022-08-11T10:32:15.899929Z","shell.execute_reply":"2022-08-11T10:32:16.080722Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Adding in augmentations \nHere we've applied an augmentation available to us through TensorFlow. ","metadata":{"papermill":{"duration":0.038372,"end_time":"2020-11-19T21:48:00.765394","exception":false,"start_time":"2020-11-19T21:48:00.727022","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def data_augment(image, label):\n    # Thanks to the dataset.prefetch(AUTO) statement in the following function this happens essentially for free on TPU. \n    # Data pipeline code is executed on the \"CPU\" part of the TPU while the TPU itself is computing gradients.\n    image = tf.image.random_flip_left_right(image)\n    return image, label","metadata":{"papermill":{"duration":0.047715,"end_time":"2020-11-19T21:48:00.851918","exception":false,"start_time":"2020-11-19T21:48:00.804203","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-11T10:32:16.084979Z","iopub.execute_input":"2022-08-11T10:32:16.085198Z","iopub.status.idle":"2022-08-11T10:32:16.090700Z","shell.execute_reply.started":"2022-08-11T10:32:16.085174Z","shell.execute_reply":"2022-08-11T10:32:16.089386Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Define data loading methods\nThe following functions will be used to load our `training`, `validation`, and `test` datasets, as well as print out the number of images in each dataset.","metadata":{"papermill":{"duration":0.038742,"end_time":"2020-11-19T21:48:00.930185","exception":false,"start_time":"2020-11-19T21:48:00.891443","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def get_training_dataset():\n    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)  \n    dataset = dataset.map(data_augment, num_parallel_calls=AUTOTUNE)  \n    dataset = dataset.repeat()\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTOTUNE)\n    return dataset","metadata":{"papermill":{"duration":0.052326,"end_time":"2020-11-19T21:48:01.021791","exception":false,"start_time":"2020-11-19T21:48:00.969465","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-11T10:32:16.094619Z","iopub.execute_input":"2022-08-11T10:32:16.095143Z","iopub.status.idle":"2022-08-11T10:32:16.103281Z","shell.execute_reply.started":"2022-08-11T10:32:16.095113Z","shell.execute_reply":"2022-08-11T10:32:16.102564Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def get_validation_dataset(ordered=False):\n    dataset = load_dataset(VALID_FILENAMES, labeled=True, ordered=ordered) \n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.cache()\n    dataset = dataset.prefetch(AUTOTUNE)\n    return dataset","metadata":{"papermill":{"duration":0.049787,"end_time":"2020-11-19T21:48:01.112145","exception":false,"start_time":"2020-11-19T21:48:01.062358","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-11T10:32:16.104375Z","iopub.execute_input":"2022-08-11T10:32:16.105246Z","iopub.status.idle":"2022-08-11T10:32:16.115954Z","shell.execute_reply.started":"2022-08-11T10:32:16.105205Z","shell.execute_reply":"2022-08-11T10:32:16.115240Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def get_test_dataset(ordered=False):\n    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTOTUNE)\n    return dataset","metadata":{"papermill":{"duration":0.050395,"end_time":"2020-11-19T21:48:01.207665","exception":false,"start_time":"2020-11-19T21:48:01.15727","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-11T10:32:16.117282Z","iopub.execute_input":"2022-08-11T10:32:16.117679Z","iopub.status.idle":"2022-08-11T10:32:16.126282Z","shell.execute_reply.started":"2022-08-11T10:32:16.117641Z","shell.execute_reply":"2022-08-11T10:32:16.125660Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def count_data_items(filenames):\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)","metadata":{"papermill":{"duration":0.05422,"end_time":"2020-11-19T21:48:01.304611","exception":false,"start_time":"2020-11-19T21:48:01.250391","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-11T10:32:16.127547Z","iopub.execute_input":"2022-08-11T10:32:16.128043Z","iopub.status.idle":"2022-08-11T10:32:16.137288Z","shell.execute_reply.started":"2022-08-11T10:32:16.128003Z","shell.execute_reply":"2022-08-11T10:32:16.136638Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\nNUM_VALIDATION_IMAGES = count_data_items(VALID_FILENAMES)\nNUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\n\nprint('Dataset: {} training images, {} validation images, {} (unlabeled) test images'.format(\n    NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES, NUM_TEST_IMAGES))","metadata":{"papermill":{"duration":0.051209,"end_time":"2020-11-19T21:48:01.396198","exception":false,"start_time":"2020-11-19T21:48:01.344989","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-11T10:32:16.138352Z","iopub.execute_input":"2022-08-11T10:32:16.138901Z","iopub.status.idle":"2022-08-11T10:32:16.155170Z","shell.execute_reply.started":"2022-08-11T10:32:16.138870Z","shell.execute_reply":"2022-08-11T10:32:16.154045Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# Brief exploratory data analysis (EDA)\nFirst we'll print out the shapes and labels for a sample of each of our three datasets:","metadata":{"papermill":{"duration":0.041086,"end_time":"2020-11-19T21:48:01.478205","exception":false,"start_time":"2020-11-19T21:48:01.437119","status":"completed"},"tags":[]}},{"cell_type":"code","source":"print(\"Training data shapes:\")\nfor image, label in get_training_dataset().take(3):\n    print(image.numpy().shape, label.numpy().shape)\nprint(\"Training data label examples:\", label.numpy())\nprint(\"Validation data shapes:\")\nfor image, label in get_validation_dataset().take(3):\n    print(image.numpy().shape, label.numpy().shape)\nprint(\"Validation data label examples:\", label.numpy())\nprint(\"Test data shapes:\")\nfor image, idnum in get_test_dataset().take(3):\n    print(image.numpy().shape, idnum.numpy().shape)\nprint(\"Test data IDs:\", idnum.numpy().astype('U')) # U=unicode string","metadata":{"papermill":{"duration":17.07767,"end_time":"2020-11-19T21:48:18.597304","exception":false,"start_time":"2020-11-19T21:48:01.519634","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-11T10:32:16.156390Z","iopub.execute_input":"2022-08-11T10:32:16.157529Z","iopub.status.idle":"2022-08-11T10:32:28.902383Z","shell.execute_reply.started":"2022-08-11T10:32:16.157459Z","shell.execute_reply":"2022-08-11T10:32:28.901595Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"The following code chunk sets up a series of functions that will print out a grid of images. The grid of images will contain images and their corresponding labels.","metadata":{"papermill":{"duration":0.044101,"end_time":"2020-11-19T21:48:18.6862","exception":false,"start_time":"2020-11-19T21:48:18.642099","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# numpy and matplotlib defaults\nnp.set_printoptions(threshold=15, linewidth=80)\n\ndef batch_to_numpy_images_and_labels(data):\n    images, labels = data\n    numpy_images = images.numpy()\n    numpy_labels = labels.numpy()\n    if numpy_labels.dtype == object: # binary string in this case, these are image ID strings\n        numpy_labels = [None for _ in enumerate(numpy_images)]\n    # If no labels, only image IDs, return None for labels (this is the case for test data)\n    return numpy_images, numpy_labels\n\ndef title_from_label_and_target(label, correct_label):\n    if correct_label is None:\n        return CLASSES[label], True\n    correct = (label == correct_label)\n    return \"{} [{}{}{}]\".format(CLASSES[label], 'OK' if correct else 'NO', u\"\\u2192\" if not correct else '',\n                                CLASSES[correct_label] if not correct else ''), correct\n\ndef display_one_plant(image, title, subplot, red=False, titlesize=16):\n    plt.subplot(*subplot)\n    plt.axis('off')\n    plt.imshow(image)\n    if len(title) > 0:\n        plt.title(title, fontsize=int(titlesize) if not red else int(titlesize/1.2), color='red' if red else 'black', fontdict={'verticalalignment':'center'}, pad=int(titlesize/1.5))\n    return (subplot[0], subplot[1], subplot[2]+1)\n\ndef display_batch_of_images(databatch, predictions=None):\n    \"\"\"This will work with:\n    display_batch_of_images(images)\n    display_batch_of_images(images, predictions)\n    display_batch_of_images((images, labels))\n    display_batch_of_images((images, labels), predictions)\n    \"\"\"\n    # data\n    images, labels = batch_to_numpy_images_and_labels(databatch)\n    if labels is None:\n        labels = [None for _ in enumerate(images)]\n        \n    # auto-squaring: this will drop data that does not fit into square or square-ish rectangle\n    rows = int(math.sqrt(len(images)))\n    cols = len(images)//rows\n        \n    # size and spacing\n    FIGSIZE = 13.0\n    SPACING = 0.1\n    subplot=(rows,cols,1)\n    if rows < cols:\n        plt.figure(figsize=(FIGSIZE,FIGSIZE/cols*rows))\n    else:\n        plt.figure(figsize=(FIGSIZE/rows*cols,FIGSIZE))\n    \n    # display\n    for i, (image, label) in enumerate(zip(images[:rows*cols], labels[:rows*cols])):\n        title = '' if label is None else CLASSES[label]\n        correct = True\n        if predictions is not None:\n            title, correct = title_from_label_and_target(predictions[i], label)\n        dynamic_titlesize = FIGSIZE*SPACING/max(rows,cols)*40+3 # magic formula tested to work from 1x1 to 10x10 images\n        subplot = display_one_plant(image, title, subplot, not correct, titlesize=dynamic_titlesize)\n    \n    #layout\n    plt.tight_layout()\n    if label is None and predictions is None:\n        plt.subplots_adjust(wspace=0, hspace=0)\n    else:\n        plt.subplots_adjust(wspace=SPACING, hspace=SPACING)\n    plt.show()","metadata":{"papermill":{"duration":0.077342,"end_time":"2020-11-19T21:48:18.808133","exception":false,"start_time":"2020-11-19T21:48:18.730791","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-11T10:32:28.904309Z","iopub.execute_input":"2022-08-11T10:32:28.904561Z","iopub.status.idle":"2022-08-11T10:32:28.921687Z","shell.execute_reply.started":"2022-08-11T10:32:28.904534Z","shell.execute_reply":"2022-08-11T10:32:28.920747Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# load our training dataset for EDA\ntraining_dataset = get_training_dataset()\ntraining_dataset = training_dataset.unbatch().batch(20)\ntrain_batch = iter(training_dataset)","metadata":{"papermill":{"duration":0.104176,"end_time":"2020-11-19T21:48:18.957003","exception":false,"start_time":"2020-11-19T21:48:18.852827","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-11T10:32:28.923150Z","iopub.execute_input":"2022-08-11T10:32:28.924017Z","iopub.status.idle":"2022-08-11T10:32:28.993283Z","shell.execute_reply.started":"2022-08-11T10:32:28.923973Z","shell.execute_reply":"2022-08-11T10:32:28.992558Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# run this cell again for another randomized set of training images\ndisplay_batch_of_images(next(train_batch))","metadata":{"papermill":{"duration":3.371477,"end_time":"2020-11-19T21:48:22.374778","exception":false,"start_time":"2020-11-19T21:48:19.003301","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-11T10:32:28.994373Z","iopub.execute_input":"2022-08-11T10:32:28.994609Z","iopub.status.idle":"2022-08-11T10:32:34.118219Z","shell.execute_reply.started":"2022-08-11T10:32:28.994585Z","shell.execute_reply":"2022-08-11T10:32:34.117428Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"You can also modify the above code to look at your `validation` and `test` data, like this:","metadata":{"papermill":{"duration":0.086379,"end_time":"2020-11-19T21:48:22.547481","exception":false,"start_time":"2020-11-19T21:48:22.461102","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# load our validation dataset for EDA\nvalidation_dataset = get_validation_dataset()\nvalidation_dataset = validation_dataset.unbatch().batch(20)\nvalid_batch = iter(validation_dataset)","metadata":{"papermill":{"duration":0.136485,"end_time":"2020-11-19T21:48:22.769878","exception":false,"start_time":"2020-11-19T21:48:22.633393","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-11T10:32:34.119501Z","iopub.execute_input":"2022-08-11T10:32:34.120031Z","iopub.status.idle":"2022-08-11T10:32:34.174844Z","shell.execute_reply.started":"2022-08-11T10:32:34.119991Z","shell.execute_reply":"2022-08-11T10:32:34.173952Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# run this cell again for another randomized set of training images\ndisplay_batch_of_images(next(valid_batch))","metadata":{"papermill":{"duration":3.155802,"end_time":"2020-11-19T21:48:26.010993","exception":false,"start_time":"2020-11-19T21:48:22.855191","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-11T10:32:34.176258Z","iopub.execute_input":"2022-08-11T10:32:34.176547Z","iopub.status.idle":"2022-08-11T10:32:38.088192Z","shell.execute_reply.started":"2022-08-11T10:32:34.176516Z","shell.execute_reply":"2022-08-11T10:32:38.087269Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# load our test dataset for EDA\ntesting_dataset = get_test_dataset()\ntesting_dataset = testing_dataset.unbatch().batch(20)\ntest_batch = iter(testing_dataset)","metadata":{"papermill":{"duration":0.232531,"end_time":"2020-11-19T21:48:26.411209","exception":false,"start_time":"2020-11-19T21:48:26.178678","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-11T10:32:38.089908Z","iopub.execute_input":"2022-08-11T10:32:38.090166Z","iopub.status.idle":"2022-08-11T10:32:38.137250Z","shell.execute_reply.started":"2022-08-11T10:32:38.090136Z","shell.execute_reply":"2022-08-11T10:32:38.136566Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# we only have one test image\ndisplay_batch_of_images(next(test_batch))","metadata":{"papermill":{"duration":1.333241,"end_time":"2020-11-19T21:48:27.900651","exception":false,"start_time":"2020-11-19T21:48:26.56741","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-11T10:32:38.138492Z","iopub.execute_input":"2022-08-11T10:32:38.139097Z","iopub.status.idle":"2022-08-11T10:32:39.569111Z","shell.execute_reply.started":"2022-08-11T10:32:38.139052Z","shell.execute_reply":"2022-08-11T10:32:39.567883Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# Building the model\n## Learning rate schedule","metadata":{"papermill":{"duration":0.230199,"end_time":"2020-11-19T21:48:28.353794","exception":false,"start_time":"2020-11-19T21:48:28.123595","status":"completed"},"tags":[]}},{"cell_type":"code","source":"lr_scheduler = keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=1e-5, \n    decay_steps=10000, \n    decay_rate=0.9)   \n#  an initially large learning rate suppresses the network from memorizing noisy data while decaying the learning rate improves the learning of complex patterns.","metadata":{"papermill":{"duration":0.248904,"end_time":"2020-11-19T21:48:28.83328","exception":false,"start_time":"2020-11-19T21:48:28.584376","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-11T10:32:39.570505Z","iopub.execute_input":"2022-08-11T10:32:39.570789Z","iopub.status.idle":"2022-08-11T10:32:39.576304Z","shell.execute_reply.started":"2022-08-11T10:32:39.570758Z","shell.execute_reply":"2022-08-11T10:32:39.575523Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"## Building our model\nIn order to ensure that our model is trained on the TPU, we build it using `with strategy.scope()`.    \n\nThis model was built using transfer learning, meaning that we have a _pre-trained model_ (ResNet50) as our base model and then the customizable model built using `tf.keras.Sequential`. \n\nNote that we're using `sparse_categorical_crossentropy` as our loss function, because we did _not_ one-hot encode our labels.\n\nKeras Documentation link:- https://keras.io/guides/transfer_learning/","metadata":{"papermill":{"duration":0.22538,"end_time":"2020-11-19T21:48:29.285377","exception":false,"start_time":"2020-11-19T21:48:29.059997","status":"completed"},"tags":[]}},{"cell_type":"code","source":"with strategy.scope():       \n    img_adjust_layer = tf.keras.layers.Lambda(tf.keras.applications.resnet50.preprocess_input, input_shape=[*IMAGE_SIZE, 3])\n    \n    base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False)\n    base_model.trainable = False\n    \n    model = tf.keras.Sequential([\n        tf.keras.layers.BatchNormalization(renorm=True),\n        img_adjust_layer,\n        base_model,\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dense(8, activation='relu'),\n        #tf.keras.layers.BatchNormalization(renorm=True),\n        tf.keras.layers.Dense(len(CLASSES), activation='softmax')  \n    ])\n    \n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=lr_scheduler, epsilon=0.001),\n        loss='sparse_categorical_crossentropy',  \n        metrics=['sparse_categorical_accuracy'])","metadata":{"papermill":{"duration":19.661572,"end_time":"2020-11-19T21:48:49.158413","exception":false,"start_time":"2020-11-19T21:48:29.496841","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-11T10:32:39.577536Z","iopub.execute_input":"2022-08-11T10:32:39.577804Z","iopub.status.idle":"2022-08-11T10:32:51.896530Z","shell.execute_reply.started":"2022-08-11T10:32:39.577774Z","shell.execute_reply":"2022-08-11T10:32:51.895375Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"loss: 1.0382 - sparse_categorical_accuracy: 0.6300 - val_loss: 1.0382 - val_sparse_categorical_accuracy: 0.6294","metadata":{}},{"cell_type":"code","source":"# Model architecture 2\n#Change - Training the base model as well.\n\nwith strategy.scope():       \n    img_adjust_layer = tf.keras.layers.Lambda(tf.keras.applications.resnet50.preprocess_input, input_shape=[*IMAGE_SIZE, 3])\n    \n    base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False)\n    base_model.trainable = True\n    \n    model = tf.keras.Sequential([\n        tf.keras.layers.BatchNormalization(renorm=True),\n        img_adjust_layer,\n        base_model,\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dense(8, activation='relu'),\n        #tf.keras.layers.BatchNormalization(renorm=True),\n        tf.keras.layers.Dense(len(CLASSES), activation='softmax')  \n    ])\n    \n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=lr_scheduler, epsilon=0.001),\n        loss='sparse_categorical_crossentropy',  \n        metrics=['sparse_categorical_accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-08-11T10:32:51.899279Z","iopub.execute_input":"2022-08-11T10:32:51.899645Z","iopub.status.idle":"2022-08-11T10:33:01.034653Z","shell.execute_reply.started":"2022-08-11T10:32:51.899597Z","shell.execute_reply":"2022-08-11T10:33:01.033312Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"### For this architecture, we get the final metric as loss: 0.3700 - sparse_categorical_accuracy: 0.8811 - val_loss: 1.0081 - val_sparse_categorical_accuracy: 0.6907. \nAlthough plot for this model is not stable and hovers a lot.\nTo get the epoch with better val_sparse_categorical_accuracy, we can use early stoping.\n\n### After applying early stopping, we get following final accuracy:-\nloss: 0.4021 - sparse_categorical_accuracy: 0.8594 - val_loss: 0.6356 - val_sparse_categorical_accuracy: 0.7752","metadata":{}},{"cell_type":"markdown","source":"# Train the model\nAs our model is training you'll see a printout for each epoch, and can also monitor TPU usage by clicking on the TPU metrics in the toolbar at the top right of your notebook.","metadata":{"papermill":{"duration":0.174404,"end_time":"2020-11-19T21:48:49.513099","exception":false,"start_time":"2020-11-19T21:48:49.338695","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# load data\ntrain_dataset = get_training_dataset()\nvalid_dataset = get_validation_dataset()","metadata":{"papermill":{"duration":0.249051,"end_time":"2020-11-19T21:48:49.936435","exception":false,"start_time":"2020-11-19T21:48:49.687384","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-11T10:33:01.036329Z","iopub.execute_input":"2022-08-11T10:33:01.036688Z","iopub.status.idle":"2022-08-11T10:33:01.176707Z","shell.execute_reply.started":"2022-08-11T10:33:01.036648Z","shell.execute_reply":"2022-08-11T10:33:01.175854Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\nVALID_STEPS = NUM_VALIDATION_IMAGES // BATCH_SIZE\n\nhistory = model.fit(train_dataset, \n                    steps_per_epoch=STEPS_PER_EPOCH, \n                    epochs=EPOCHS,\n                    validation_data=valid_dataset,\n                    validation_steps=VALID_STEPS, \n                   callbacks= tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5))","metadata":{"papermill":{"duration":956.681695,"end_time":"2020-11-19T22:04:46.795744","exception":false,"start_time":"2020-11-19T21:48:50.114049","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-11T10:33:01.177878Z","iopub.execute_input":"2022-08-11T10:33:01.178108Z","iopub.status.idle":"2022-08-11T10:58:49.124842Z","shell.execute_reply.started":"2022-08-11T10:33:01.178083Z","shell.execute_reply":"2022-08-11T10:58:49.124100Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"With model.summary() we'll see a printout of each of our layers, their corresponding shape, as well as the associated number of parameters. Notice that at the bottom of the printout we'll see information on the total parameters, trainable parameters, and non-trainable parameters. Because we're using a pre-trained model, we expect there to be a large number of non-trainable parameters (because the weights have already been assigned in the pre-trained model).","metadata":{"papermill":{"duration":1.26977,"end_time":"2020-11-19T22:04:49.3763","exception":false,"start_time":"2020-11-19T22:04:48.10653","status":"completed"},"tags":[]}},{"cell_type":"code","source":"model.summary()","metadata":{"papermill":{"duration":1.344562,"end_time":"2020-11-19T22:04:51.988755","exception":false,"start_time":"2020-11-19T22:04:50.644193","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-11T10:58:49.128731Z","iopub.execute_input":"2022-08-11T10:58:49.129419Z","iopub.status.idle":"2022-08-11T10:58:49.156448Z","shell.execute_reply.started":"2022-08-11T10:58:49.129373Z","shell.execute_reply":"2022-08-11T10:58:49.155492Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"# Evaluating our model\nThe first chunk of code is provided to show you where the variables in the second chunk of code came from. As you can see, there's a lot of room for improvement in this model, but because we're using TPUs and have a relatively short training time, we're able to iterate on our model fairly rapidly.","metadata":{"papermill":{"duration":1.245239,"end_time":"2020-11-19T22:04:54.493139","exception":false,"start_time":"2020-11-19T22:04:53.2479","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# print out variables available to us\nprint(history.history.keys())","metadata":{"papermill":{"duration":1.31245,"end_time":"2020-11-19T22:04:57.054025","exception":false,"start_time":"2020-11-19T22:04:55.741575","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-11T10:58:49.157781Z","iopub.execute_input":"2022-08-11T10:58:49.158028Z","iopub.status.idle":"2022-08-11T10:58:49.163052Z","shell.execute_reply.started":"2022-08-11T10:58:49.157999Z","shell.execute_reply":"2022-08-11T10:58:49.162338Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# create learning curves to evaluate model performance\nhistory_frame = pd.DataFrame(history.history)\nhistory_frame.loc[:, ['loss', 'val_loss']].plot()\nhistory_frame.loc[:, ['sparse_categorical_accuracy', 'val_sparse_categorical_accuracy']].plot();","metadata":{"papermill":{"duration":1.671861,"end_time":"2020-11-19T22:04:59.983272","exception":false,"start_time":"2020-11-19T22:04:58.311411","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-11T10:58:49.164298Z","iopub.execute_input":"2022-08-11T10:58:49.164627Z","iopub.status.idle":"2022-08-11T10:58:49.658775Z","shell.execute_reply.started":"2022-08-11T10:58:49.164595Z","shell.execute_reply":"2022-08-11T10:58:49.657692Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"# Making predictions\nNow that we've trained our model we can use it to make predictions! ","metadata":{"papermill":{"duration":1.326243,"end_time":"2020-11-19T22:05:02.628032","exception":false,"start_time":"2020-11-19T22:05:01.301789","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# this code will convert our test image data to a float32 \ndef to_float32(image, label):\n    return tf.cast(image, tf.float32), label","metadata":{"papermill":{"duration":1.270192,"end_time":"2020-11-19T22:05:05.187694","exception":false,"start_time":"2020-11-19T22:05:03.917502","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-11T10:58:49.660165Z","iopub.execute_input":"2022-08-11T10:58:49.660423Z","iopub.status.idle":"2022-08-11T10:58:49.665269Z","shell.execute_reply.started":"2022-08-11T10:58:49.660394Z","shell.execute_reply":"2022-08-11T10:58:49.664317Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"test_ds = get_test_dataset(ordered=True) \ntest_ds = test_ds.map(to_float32)\n\nprint('Computing predictions...')\ntest_images_ds = testing_dataset\ntest_images_ds = test_ds.map(lambda image, idnum: image)\nprobabilities = model.predict(test_images_ds)\npredictions = np.argmax(probabilities, axis=-1)\nprint(predictions)","metadata":{"papermill":{"duration":15.776858,"end_time":"2020-11-19T22:05:22.235661","exception":false,"start_time":"2020-11-19T22:05:06.458803","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-11T10:58:49.666801Z","iopub.execute_input":"2022-08-11T10:58:49.667240Z","iopub.status.idle":"2022-08-11T10:58:59.604829Z","shell.execute_reply.started":"2022-08-11T10:58:49.667191Z","shell.execute_reply":"2022-08-11T10:58:59.603860Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"# Creating a submission file\nNow that we've trained a model and made predictions we're ready to submit to the competition! You can run the following code below to get your submission file.","metadata":{"papermill":{"duration":1.271799,"end_time":"2020-11-19T22:05:24.759257","exception":false,"start_time":"2020-11-19T22:05:23.487458","status":"completed"},"tags":[]}},{"cell_type":"code","source":"print('Generating submission.csv file...')\ntest_ids_ds = test_ds.map(lambda image, idnum: idnum).unbatch()\ntest_ids = next(iter(test_ids_ds.batch(NUM_TEST_IMAGES))).numpy().astype('U') # all in one batch\nnp.savetxt('submission.csv', np.rec.fromarrays([test_ids, predictions]), fmt=['%s', '%d'], delimiter=',', header='id,label', comments='')\n!head submission.csv","metadata":{"papermill":{"duration":2.185537,"end_time":"2020-11-19T22:05:28.241723","exception":false,"start_time":"2020-11-19T22:05:26.056186","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-11T10:58:59.606061Z","iopub.execute_input":"2022-08-11T10:58:59.606318Z","iopub.status.idle":"2022-08-11T10:59:00.859872Z","shell.execute_reply.started":"2022-08-11T10:58:59.606288Z","shell.execute_reply":"2022-08-11T10:59:00.858758Z"},"trusted":true},"execution_count":33,"outputs":[]}]}